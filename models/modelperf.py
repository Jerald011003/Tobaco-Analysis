# -*- coding: utf-8 -*-
"""MikeNagbu.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b0AGWUcdpYZzFNa7rUn7GvdO15yQ9QTK

# **Youth Tobacco Survey (YTS) Data**

**Libraries**
"""

import warnings
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.impute import SimpleImputer
from sklearn.model_selection import GridSearchCV

"""**Preferences**"""

warnings.filterwarnings('ignore')

sns.set_theme(style='whitegrid', font='serif')

DATASETURL = 'https://raw.githubusercontent.com/Jerald011003/Tobaco-Analysis/refs/heads/main/datasets/Youth_Tobacco_Survey__YTS__Data.csv'

"""# **I. Exploratory Data Analysis**"""

data = pd.read_csv(DATASETURL)

data.head()

data.info()

data.describe().T

data.columns
num_cols = data.select_dtypes(include=np.number).columns
cat_cols = data.select_dtypes(include='object').columns

print(f'Numerical Columns\n{num_cols}\n')
print(f'Categorical Columns\n{cat_cols}')

"""# **II. Data Cleaning and Preprocessing**"""

# Summation of missing values
data.isnull().sum()

# No. of duplications
data.duplicated().sum()

irrelevant_columns = [
    'TopicTypeId', 'Data_Value_Footnote_Symbol', 'Data_Value_Footnote',
    'Data_Value_Std_Err', 'Low_Confidence_Limit', 'High_Confidence_Limit',
    'Sample_Size', 'GeoLocation'
]

data_cleaned = data.drop(columns=irrelevant_columns)

data_cleaned.columns = data_cleaned.columns.str.strip()

data_cleaned = data_cleaned.dropna(subset=[col for col in ['Low_Confidence_Limit', 'High_Confidence_Limit'] if col in data_cleaned.columns])

# Fill missing values in categorical columns with 'True'
categorical_columns = data_cleaned.select_dtypes(include=['object']).columns
data_cleaned[categorical_columns] = data_cleaned[categorical_columns].fillna(True)

# Fill missing values in numeric columns with the column mean
numeric_columns = data_cleaned.select_dtypes(include=['float64', 'int64']).columns
data_cleaned[numeric_columns] = data_cleaned[numeric_columns].fillna(data_cleaned[numeric_columns].mean())

print("\nMissing values after cleaning:")
data_cleaned.isnull().sum()

data_cleaned.head()

num_cols = data_cleaned.select_dtypes(include=np.number).columns
cat_cols = data_cleaned.select_dtypes(include='object').columns

print(f'Numerical Columns\n{num_cols}\n')
print(f'Categorical Columns\n{cat_cols}')

"""# III. Data Visualization"""

# Visualization 1: Trend of Tobacco-Related Measures Over Time (Line Chart)
plt.figure(figsize=(12, 6))
measure_trend = data_cleaned.groupby(['YEAR', 'MeasureDesc']).size().unstack().fillna(0)
measure_trend.plot(kind='line', ax=plt.gca())
plt.title("Trends in Tobacco-Related Measures Over Time")
plt.xlabel("Year")
plt.ylabel("Count")
plt.legend(title="Measure Description")
plt.tight_layout()
plt.show()

"""Trends in Tobacco-Related Measures Over Time (Line Chart)
* This line chart illustrates changes in tobacco-related measures (e.g., "Smoking Status," "User Status") across the years. The lines for each measure help reveal patterns or shifts over time, indicating trends in smoking behaviors or tobacco use within the population.
"""

# Visualization 1: Breakdown of Tobacco Use by Age
plt.figure(figsize=(10, 6))
sns.countplot(data=data_cleaned, x='Age', hue='MeasureDesc')
plt.title("Demographic Breakdown of Tobacco Use by Age")
plt.xlabel("Age")
plt.ylabel("Count")
plt.legend(title="Measure Description")
plt.tight_layout()
plt.show()

"""Demographic Breakdown of Tobacco Use by Age (Bar Plot)
* This bar plot illustrates the demographic breakdown of tobacco use across different age groups. The x-axis represents various age categories, while the y-axis indicates the count of tobacco-related measures for each age group. Each bar is color-coded according to different measure descriptions, providing insights into how tobacco use varies among various demographics. The legend clarifies which measure corresponds to each color, enabling viewers to quickly understand the distribution and prevalence of tobacco use across ages.
"""

# Visualization 3: Heatmap of Data Values by Education and Topic (Heatmap)

pivot_table = data_cleaned.pivot_table(
    index='Education',
    columns='TopicDesc',
    values='Data_Value',
    aggfunc='mean'
)

plt.figure(figsize=(12, 8))
sns.heatmap(pivot_table, annot=True, fmt=".2f", cmap="YlGnBu")
plt.title('Heatmap of Data Values by Education and Topic')
plt.xlabel('Topic')
plt.ylabel('Education')
plt.show()

"""Heatmap of Data Values by Education and Topic (Heatmap)

*   This heatmap illustrates the relationship between educational attainment and various tobacco-related measures across different topics. Each cell's color intensity indicates the average value of the tobacco-related measures for each educational level, allowing for a clear visualization of how education influences awareness and engagement with tobacco-related issues.

"""

# Visualization 4: Year and Demographic Combined Analysis (Facet Grid)

g = sns.FacetGrid(data_cleaned, col='Gender', hue='MeasureDesc', height=4, aspect=1.2, col_order=['Male', 'Female'])
g.map_dataframe(sns.histplot, x='YEAR', multiple='stack')
g.add_legend(title="Measure Description")
g.set_axis_labels("Year", "Count")
g.set_titles("{col_name} Tobacco Use Trends Over Time")
plt.suptitle("Combined Analysis of Tobacco Use Trends by Gender Over Time", y=1.05)
plt.tight_layout()
plt.show()

"""Combined Analysis of Tobacco Use Trends by Gender Over Time (Facet Grid)


*   This facet grid shows tobacco use trends over time, with separate histograms for each gender. Each subplot represents either male or female, and the stacked bars show the annual distribution for each tobacco measure. This view combines gender and time trends, revealing any notable differences in smoking-related behaviors across genders over the years.

# **IV. Model Development**
"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report

# Drop specified columns
columns_to_drop = [
    "YEAR", "LocationAbbr", "LocationDesc", "DataSource",
    "TopicType", "Data_Value_Type", "Gender", "StratificationID2",
    "StratificationID3", "Data_Value_Unit"
]
data_filtered = data_cleaned.drop(columns=columns_to_drop, errors='ignore')

for col in data_filtered.columns:
    if data_filtered[col].dtype == 'bool':
        data_filtered[col] = data_filtered[col].astype(int)
    elif data_filtered[col].dtype == 'object':
        data_filtered[col] = data_filtered[col].astype(str)

label_encoders = {col: LabelEncoder() for col in data_filtered.select_dtypes(include='object').columns}
for col, le in label_encoders.items():
    data_filtered[col] = le.fit_transform(data_filtered[col])


X = data_filtered.drop(columns="Response")
y = data_filtered["Response"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

imputer = SimpleImputer(strategy="mean")
X_train = imputer.fit_transform(X_train)
X_test = imputer.transform(X_test)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "Support Vector Machine": SVC(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42)
}

model_performance = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, output_dict=True)
    model_performance[name] = {"Accuracy": accuracy, "Classification Report": report}

model_performance

"""# **V. Model Evaluation**"""

model_performance = {}

def evaluate_model(model, X_train, y_train, X_test, y_test):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, output_dict=True)
    return accuracy, report, y_pred

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Support Vector Machine": SVC(),
    "Random Forest": RandomForestClassifier(),
    "Gradient Boosting": GradientBoostingClassifier()
}

for name, model in models.items():
    accuracy, report, y_pred = evaluate_model(model, X_train, y_train, X_test, y_test)

    model_performance[name] = {
        "Accuracy": accuracy,
        "Classification Report": report,
        "Confusion Matrix": confusion_matrix(y_test, y_pred)
    }

    if accuracy < 0.85:
        print(f"{name} did not meet the accuracy threshold. Tuning hyperparameters...")

        if name == "Random Forest":
            param_grid = {
                'n_estimators': [50, 100, 200],
                'max_depth': [None, 10, 20, 30],
                'min_samples_split': [2, 5, 10]
            }
            grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')
            grid_search.fit(X_train, y_train)
            best_model = grid_search.best_estimator_
            accuracy, report, y_pred = evaluate_model(best_model, X_train, y_train, X_test, y_test)

            model_performance[name] = {
                "Accuracy": accuracy,
                "Classification Report": report,
                "Confusion Matrix": confusion_matrix(y_test, y_pred)
            }

for name, metrics in model_performance.items():
    print(f"Model: {name}")
    print(f"Accuracy: {metrics['Accuracy']* 100:.2f}%")
    print("Classification Report:")
    print(metrics["Classification Report"])
    print("Confusion Matrix:")
    print(metrics["Confusion Matrix"])
    print("-" * 40)